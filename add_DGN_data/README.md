# Add DGN data

## Description
> This set of scripts downloads DGN data and formats the data into a gSYNC format.


## -1. specify working directory
>  ```bash
wd="/scratch/aob2x/dest"
>  ```

## 0. Download all DGN data
> Needs a tab delimited file with jobID, prefix, path to DGN bz2 file: `DEST/add_DGN_data/dgn.list` <br/>
> Note that job 4 will fail. Why? Because 4 is the fourth line on DGN website for the DSPR. I don't think that we need to include that one.<br/>
```bash
sbatch --array=1-8 ${wd}/DEST/add_DGN_data/downloadDGN.sh
```
> OUT: ${wd}/dest/dgn/rawData<br/>


## 1. Unpack
> Each tarball is a bit different so the unpack scripts are different for each 1-8 (minus 4), from above. <br/>
> ```bash
sbatch --array=1-8 ${wd}/DEST/add_DGN_data/unpack.sh
>```

## 2. Wide to long
> should be 4725 jobs <br/>
>```bash
cd ${wd}/dgn/wideData/; ls * | tr '\t' '\n' | awk '{print >NR"\t"$0}' > ${wd}/dgn/dgn_wideFiles.delim
sbatch --array=1-$( tail -n1 ${wd}/dgn/dgn_wideFiles.delim | >cut -f1 ) ${wd}/DEST/add_DGN_data/wide2long.sh
>```
> A quick check to make sure things look good:
> `w2l_check.R`

## 3. Format reference genome
>```bash
sbatch ${wd}/DEST/add_DGN_data/getRefGenome.sh
>```

> Check that length of reference geomes are the same as the DGP long files: <br/>
> `wc -l ${wd}/referenceGenome/r5/2L.long` <br/>
> `wc -l ${wd}/dgn/longData/B_B04_Chr2L.seq.long` <br/>
> `wc -l ${wd}/referenceGenome/r5/3L.long` <br/>
> `wc -l ${wd}/dgn/longData/B_B04_Chr3L.seq.long` <br/>
> the reference geome is one line longer than the DGN data but that is due to a trailing empty line. No prob. <br/>

## 4. Generate gSYNC files for each population
>```bash
sbatch ${wd}/DEST/add_DGN_data/pop_chr_maker.sh
nJobs=$( tail -n1 ${wd}/dgn/pops.delim | cut -f1 )
rm ${wd}/dgn/confirm_files
sbatch --array=1-${nJobs} ${wd}/DEST/add_DGN_data/makePopGenomeSync.sh
```


76,77,78,79,80,116,117,118,119,120
#sacct -j 12282717
















  ### 3. Make per-population SYNC file
  ~~> RUN: `ls /scratch/aob2x/dest/dgn/longData/* | rev | cut -f1 -d'/' | rev | cut -f1 -d'_' | sort | uniq | awk '{print "2L\t"$0"\n2R\t"$0"\n3L\t"$0"\n3R\t"$0"\nX\t"$0"\n"}' > /scratch/aob2x/dest/dgn/pops.delim` <br/>~~
  > RUN: `sbatch /scratch/aob2x/dest/DEST/add_DGN_data/pop_chr_maker.sh`
  > RUN: `nJobs=$( tail -n1 /scratch/aob2x/dest/dgn/pops.delim | cut -f1 )` <br/>
  > RUN: `sbatch --array=1-${nJobs} /scratch/aob2x/dest/DEST/add_DGN_data/makePopSync.sh` <br/>

## Identify polymorphic sites and merge those with DrosRTEC & DrosEU data
  ### 4. Identify the positions of all polymorphic sites <br/>
  > RUN: `sbatch --array=1-5 /scratch/aob2x/dest/DEST/add_DGN_data/findAllSites.sh` <br/>

  ### 5. Liftover sites to R6 <br/>
  > Need to install 'liftOver' first from : `wget -P ~ http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/liftOver` <br/>
  > RUN: `wget -P /scratch/aob2x/dest/dgn/liftoverChains/ http://hgdownload.soe.ucsc.edu/goldenPath/dm6/liftOver/dm6ToDm3.over.chain.gz` <br/>
  > RUN: `wget -P /scratch/aob2x/dest/dgn/liftoverChains/ http://hgdownload.soe.ucsc.edu/goldenPath/dm3/liftOver/dm3ToDm6.over.chain.gz` <br/>
  > RUN: `sbatch --array=1-5 /scratch/aob2x/dest/DEST/add_DGN_data/liftover_r5_to_r6.sh` <br/>
  > RUN: `cat /scratch/aob2x/dest/dgn/sitesData/dgn_sites_*.dm6.bed > /scratch/aob2x/dest/dgn/sitesData/dgn_sites.dm6.bed`

  ### 6. Get DrosRTEC SNP list <br/>
  > 1. The DrosRTEC sites require the `mel_freqdp_*_042016_Ne_fixed.Rdata` files which were generated by H. Machado as part of [this manuscript](https://www.biorxiv.org/content/10.1101/337543v2.abstract). At some point, this link will point to the DataDryad repo. <br/>
  > RUN `sbatch /scratch/aob2x/dest/DEST/add_DGN_data/getSNP_list_drosRTEC.sh` <br/>

  ### 7. Get DrosEU SNP list
  > 1. The DrosEU sties require [this VCF file](https://digital.csic.es/bitstream/10261/180630/1/DrosEU-mac002-mic10-mc20-mf0001-mif02-filtered-ann.vcf.gz),
  > which is from [the first DrosEU paper](https://www.biorxiv.org/content/10.1101/313759v2.abstract). <br/>
  > RUN: `wget --no-check-certificate -P /scratch/aob2x/dest/drosEU https://digital.csic.es/bitstream/10261/180630/1/DrosEU-mac002-mic10-mc20-mf0001-mif02-filtered-ann.vcf.gz` <br/>
  > RUN: `sbatch /scratch/aob2x/dest/DEST/add_DGN_data/getSNP_list_drosEU.sh` <br/>

  ### 8. Merge DGN, DrosEU, DrosRTEC snp lists
  > Also filters down to 2,3,X <br/>
  > RUN: `sbatch /scratch/aob2x/dest/DEST/add_DGN_data/mergeSNPlist.sh`
  > Any duplicates? Double check: `/scratch/aob2x/dest/DEST/add_DGN_data/check4dups.R`
  > Okay, all checks out. ~19.5M sites

  ~~### 9. Compare with older version of DEST snp list; tidy up~~
  ~~> The previous iteration of the DEST dataset used a SNP list generated from DrosEU2014 + DrosRTEC + DGN{DPGP3/CO/GA/GU/NG}. That list has 14M sites. The goal here~~
  ~~> is to generate the new master list of SNPs for DEST (15.7M) in both dm3 and dm6 and to pull out the 11M new SNPs identified with this pipeline.</br>~~
  ~~> The SNP list (/scratch/aob2x/dest/dest/drosRTEC_DrosEU_DGRP_SNPs_filtered.pos.dm6.bed) for the previous version was generated with `DEST/add_DGN_data/get_dpgp_workstation.sh` <br/>~~
  ~~> RUN: `sbatch /scratch/aob2x/dest/DEST/add_DGN_data/final_SNP_list.sh``~~

  ### 10. Generate filtered set based on Repbase for R6
  > RepeatMasker file: `wget -P /scratch/aob2x/dest/referenceGenome/r6 http://hgdownload.soe.ucsc.edu/goldenPath/dm6/bigZips/dm6.fa.out.gz`
  > TRF file: `wget -P /scratch/aob2x/dest/referenceGenome/r6/ http://hgdownload.soe.ucsc.edu/goldenPath/dm6/bigZips/dm6.trf.bed.gz`

  > A little parsing of the RepeatMasker file:<br/>
  > `zcat /scratch/aob2x/dest/referenceGenome/r6/dm6.fa.out.gz | sed '1,3d' | sed -E 's/( ){1,}/,/g'| cut -d',' -f6,7,8 | tr ',' '\t' | grep 'chr' - > /scratch/aob2x/dest/referenceGenome/r6/dm6.rep.bed` <br/>
  > `gunzip /scratch/aob2x/dest/referenceGenome/r6/dm6.trf.bed.gz` <br/>

  > RUN: `sbatch /scratch/aob2x/dest/DEST/add_DGN_data/filterFinal.sh`

  ### 11. Compress and copy to http pass through directory
  `gzip /scratch/aob2x/dest/dest/dgn_drosRTEC_drosEU.sites.noMerge.noDups.noRep.dm6.dm6Tag.bed -c > \
  /project/berglandlab/DEST/dgn_drosRTEC_drosEU.sites.noMerge.noDups.noRep.dm6.dm6Tag.bed.gz`

## DGN SYNC files for full list of SNPs
  ### 12. Convert full site list back to dm3
  > This is done in step 10. Generates file `/scratch/aob2x/dest/dest/dgn_drosRTEC_drosEU.sites.noMerge.noDups.noRep.dm3.dm6Tag.bed`
  > generate dm3 id sorted file: `cat /scratch/aob2x/dest/dest/dgn_drosRTEC_drosEU.sites.noMerge.noDups.noRep.dm3.dm6Tag.bed | awk '{print $1"_"$2"\t"$0}' | sort -k1b,1 > /scratch/aob2x/dest/dest/dgn_drosRTEC_drosEU.sites.noMerge.noDups.noRep.dm3.dm6Tag.bed.dm3IDsort`

  ### 13. Remake population SYNC files at full set of known sites
  > RUN: `nJobs=$( tail -n1 /scratch/aob2x/dest/dgn/pops.delim | cut -f1 )`
  > RUN: `sbatch --array=1-${nJobs} /scratch/aob2x/dest/DEST/add_DGN_data/sync_knownSites.sh`
  > RUN: `wc -l /scratch/aob2x/dest/dgn/syncData/*2L.dm6.sync | grep -v "total"| sed -e 's/[[:space:]]\+/,/g' | cut -f2 -d',' | sort | uniq`
         `wc -l /scratch/aob2x/dest/dgn/syncData/*2R.dm6.sync | grep -v "total"| sed -e 's/[[:space:]]\+/,/g' | cut -f2 -d',' | sort | uniq`
         `wc -l /scratch/aob2x/dest/dgn/syncData/*3L.dm6.sync | grep -v "total"| sed -e 's/[[:space:]]\+/,/g' | cut -f2 -d',' | sort | uniq`
         `wc -l /scratch/aob2x/dest/dgn/syncData/*3R.dm6.sync | grep -v "total"| sed -e 's/[[:space:]]\+/,/g' | cut -f2 -d',' | sort | uniq`
         `wc -l /scratch/aob2x/dest/dgn/syncData/*X.dm6.sync | grep -v "total"| sed -e 's/[[:space:]]\+/,/g' | cut -f2 -d',' | sort | uniq`

  ### 14. Merge DGN data
  > RUN: `nJobs=$( ls /scratch/aob2x/dest/dgn/syncData/*dm6.sync | cut -f1 -d'_' | rev | cut -f1 -d'/' | rev | sort | uniq | wc -l )`
  > RUN: `sbatch --array=1-${nJobs} /scratch/aob2x/dest/DEST/add_DGN_data/rbindSync.sh`
  > ~~ijob -c1 -p standard -A berglandlab~~
  > RUN: `paste  -d'\t' /scratch/aob2x/dest/dgn/syncData/*_genome.dm6.sync | \
          awk '{if(NF==140) {
                  printf $1"\t"$2"\t"$3"\t"
                  for(i=4; i<=NF; i=i+4) {
                    printf $i
                    if(i<NF) printf"\t"
                    if(i==NF) printf"\n"
                  }
                }
                }' > /scratch/aob2x/dest/dgn/finalSync/dgn.dm6.sync`

  ### 15. BGzip compress whole genome, per population SYNC datasets
  ### borrows code from step #3
  > RUN: `nJobs=$( tail -n1 /scratch/aob2x/dest/dgn/pops.delim | cut -f1 )` <br/>
  > RUN: `sbatch --array=1-${nJobs} /scratch/aob2x/dest/DEST/add_DGN_data/makePopGenomeSync.sh` <br/>

  > RUN: ls /scratch/aob2x/dest/dgn/syncData/*dm6.sync | cut -f1 -d'_' | rev | cut -f1 -d'/' | rev | sort | uniq | wc -l > /scratch/aob2x/dest/dgn/finalSync/dgn.dm6.sync.meta




  ### 15. Merge DGN, DrosRTEC, DrosEU datasets
  RUN: `wc -l /scratch/aob2x/dest/dest/dgn_drosRTEC_drosEU.sites.noMerge.noDups.noRep.dm6.dm6Tag.bed` 18467033
  RUN: `wc -l /scratch/aob2x/dest/drosRTEC/DrosRTEC.sync.new` : 14561208
  RUN: `wc -l /scratch/aob2x/dest/dgn/finalSync/dgn.dm6.sync` : 18437133
  RUN: `wc -l /scratch/aob2x/dest/drosEU/2020_jan/DrosEU_dgn_drosRTEC_drosEU.sites.dm6.noRep.sync` 18471704

  what?

  cut -f 5 /scratch/aob2x/dest/drosEU/2020_jan/DrosEU_dgn_drosRTEC_drosEU.sites.dm6.noRep.sync | head -n1000000 | \
  awk -F':' '{
    pm=0
    for(i=1; i<=NF; i++) {
      if($i>0) pm++
    }
    print pm
  }' | sort | uniq -c


  zcat DrosEU.sync.gz | head -n1000000 | cut -f 5 | \
  awk -F':' '{
    pm=0
    for(i=1; i<=NF; i++) {
      if($i>0) pm++
    }
    print pm
  }' | sort | uniq -c


  cut -f 4 /scratch/aob2x/dest/drosRTEC/DrosRTEC.sync.new | head -n1000000 | \
  awk -F':' '{
    pm=0
    for(i=1; i<=NF; i++) {
      if($i>0) pm++
    }
    print pm
  }' | sort | uniq -c


cut -f 3 /scratch/aob2x/dest/drosRTEC/DrosRTEC.sync.new | head
cut -f 3 /scratch/aob2x/dest/drosEU/2020_jan/DrosEU_dgn_drosRTEC_drosEU.sites.dm6.noRep.sync | head
